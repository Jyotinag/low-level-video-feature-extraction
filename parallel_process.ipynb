{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel\n",
    "from scipy.stats import entropy\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "\n",
    "def extract_optical_flow(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_frame = None\n",
    "    optical_flows = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if prev_frame is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_frame, gray_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            flow_magnitude, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            optical_flows.append(np.mean(flow_magnitude))\n",
    "        prev_frame = gray_frame\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(optical_flows, fps)\n",
    "\n",
    "def extract_hog_features(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    hog_features = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = rgb2gray(frame)\n",
    "        hog_feature = hog(gray_frame, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=False)\n",
    "        hog_features.append(np.mean(hog_feature))\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(hog_features, fps)\n",
    "\n",
    "def extract_color_histogram(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    color_histograms = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        hist_b = cv2.calcHist([frame], [0], None, [256], [0, 256])\n",
    "        hist_g = cv2.calcHist([frame], [1], None, [256], [0, 256])\n",
    "        hist_r = cv2.calcHist([frame], [2], None, [256], [0, 256])\n",
    "        color_hist = np.concatenate((hist_b, hist_g, hist_r)).flatten()\n",
    "        color_histograms.append(np.mean(color_hist))\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(color_histograms, fps)\n",
    "\n",
    "def extract_edge_detection(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    edge_intensities = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        edges = sobel(gray_frame)\n",
    "        edge_intensity = np.mean(edges)\n",
    "        edge_intensities.append(edge_intensity)\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(edge_intensities, fps)\n",
    "\n",
    "def extract_scene_cuts(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_hist = None\n",
    "    scene_cuts = []\n",
    "    cuts_per_second = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist = cv2.calcHist([gray_frame], [0], None, [256], [0, 256])\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "        if prev_hist is not None:\n",
    "            diff = np.sum(np.abs(hist - prev_hist))\n",
    "            if diff > 0.4:  # Threshold to detect scene cuts\n",
    "                cuts_per_second += 1\n",
    "\n",
    "        prev_hist = hist\n",
    "\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) % fps == 0:\n",
    "            scene_cuts.append(cuts_per_second)\n",
    "            cuts_per_second = 0\n",
    "\n",
    "    cap.release()\n",
    "    return scene_cuts\n",
    "\n",
    "def extract_saliency(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    saliency_scores = []\n",
    "\n",
    "    saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        success, saliency_map = saliency.computeSaliency(frame)\n",
    "        saliency_score = np.mean(saliency_map)\n",
    "        saliency_scores.append(saliency_score)\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(saliency_scores, fps)\n",
    "\n",
    "def extract_temporal_smoothness(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_frame = None\n",
    "    smoothness_values = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if prev_frame is not None:\n",
    "            diff = np.mean(np.abs(gray_frame - prev_frame))\n",
    "            smoothness_values.append(diff)\n",
    "        prev_frame = gray_frame\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(smoothness_values, fps)\n",
    "\n",
    "def extract_flicker_brightness(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    brightness_flickers = []\n",
    "    prev_brightness = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        brightness = np.mean(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        if prev_brightness is not None:\n",
    "            flicker = abs(brightness - prev_brightness)\n",
    "            brightness_flickers.append(flicker)\n",
    "        prev_brightness = brightness\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(brightness_flickers, fps)\n",
    "\n",
    "def extract_spectral_entropy(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    spectral_entropies = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fourier_transform = np.fft.fft2(gray_frame)\n",
    "        magnitude_spectrum = np.abs(fourier_transform)\n",
    "        spectral_entropy = shannon_entropy(magnitude_spectrum)\n",
    "        spectral_entropies.append(spectral_entropy)\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(spectral_entropies, fps)\n",
    "\n",
    "def extract_spatial_frequency(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    spatial_frequencies = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frequency_spectrum = np.fft.fftshift(np.fft.fft2(gray_frame))\n",
    "        magnitude_spectrum = np.abs(frequency_spectrum)\n",
    "        spatial_frequency = np.mean(magnitude_spectrum)\n",
    "        spatial_frequencies.append(spatial_frequency)\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(spatial_frequencies, fps)\n",
    "\n",
    "def extract_luminance_contrast(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    luminance_values = []\n",
    "    contrast_values = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        luminance = np.mean(gray_frame)\n",
    "        contrast = gray_frame.std()\n",
    "        luminance_values.append(luminance)\n",
    "        contrast_values.append(contrast)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    luminance_downsampled = downsample_to_1hz(luminance_values, fps)\n",
    "    contrast_downsampled = downsample_to_1hz(contrast_values, fps)\n",
    "\n",
    "    return luminance_downsampled, contrast_downsampled\n",
    "\n",
    "def extract_texture_features(video_path, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    texture_contrasts = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        glcm = graycomatrix(gray_frame, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "        texture_contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        texture_contrasts.append(texture_contrast)\n",
    "\n",
    "    cap.release()\n",
    "    return downsample_to_1hz(texture_contrasts, fps)\n",
    "\n",
    "def downsample_to_1hz(feature_values, fps):\n",
    "    \"\"\"Downsamples the feature values to 1Hz (1 value per second).\"\"\"\n",
    "    return [np.mean(feature_values[i:i + fps]) for i in range(0, len(feature_values), fps)]\n",
    "\n",
    "def process_video_features(video_path):\n",
    "    fps = 60  # Adjust according to the video fps\n",
    "    features = {\n",
    "        \"optical_flow\": extract_optical_flow(video_path, fps),\n",
    "        \"hog_features\": extract_hog_features(video_path, fps),\n",
    "        \"color_histogram\": extract_color_histogram(video_path, fps),\n",
    "        \"optical_flow_entropy\": extract_optical_flow(video_path, fps),\n",
    "        \"edge_intensity\": extract_edge_detection(video_path, fps),\n",
    "        \"scene_cuts\": extract_scene_cuts(video_path, fps),\n",
    "        \"temporal_smoothness\": extract_temporal_smoothness(video_path, fps),\n",
    "        \"brightness_flicker\": extract_flicker_brightness(video_path, fps),\n",
    "        \"spectral_entropy\": extract_spectral_entropy(video_path, fps),\n",
    "        \"spatial_frequency\": extract_spatial_frequency(video_path, fps),\n",
    "        \"luminance\": extract_luminance_contrast(video_path, fps)[0],\n",
    "        \"contrast\": extract_luminance_contrast(video_path, fps)[1],\n",
    "        \"texture_contrast\": extract_texture_features(video_path, fps)\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Example Usage\n",
    "video_file = '14_video.mkv'  # Replace with your video file path\n",
    "df = process_video_features(video_file)\n",
    "df = df.head(840)\n",
    "print(df.head())\n",
    "df.to_csv(\"14_video_features.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'saliency'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m saliency \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaliency\u001b[49m\u001b[38;5;241m.\u001b[39mStaticSaliencyFineGrained_create()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'saliency'"
     ]
    }
   ],
   "source": [
    "saliency = cv2.saliency.StaticSaliencyFineGrained_create()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "save",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
