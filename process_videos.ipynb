{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mean    median\n",
      "0    0.178822  0.154815\n",
      "1    0.100140  0.084262\n",
      "2    0.104509  0.100199\n",
      "3    0.121259  0.119429\n",
      "4    0.089803  0.093231\n",
      "..        ...       ...\n",
      "893  3.825157  4.495791\n",
      "894  3.305480  2.956156\n",
      "895  5.185573  6.372876\n",
      "896  5.485275  5.246538\n",
      "897  3.169283  3.697870\n",
      "\n",
      "[898 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "video_file = '29_video.mkv'  # Replace with your video file path\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Frames per second of the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frames in the video\n",
    "\n",
    "# Calculate the frame range\n",
    "duration_seconds = 15 * 60  # 15 minutes in seconds\n",
    "frames_to_process = duration_seconds * fps  # Frames to process for 15 minutes\n",
    "end_frame = total_frames - (60 * fps)  # Exclude the last 60 seconds\n",
    "start_frame = max(0, end_frame - frames_to_process)  # Start frame for the last 15 minutes excluding last 60 seconds\n",
    "\n",
    "# Initialize parameters for optical flow calculation\n",
    "prev_gray = None\n",
    "optical_flow_values = []\n",
    "\n",
    "# Set the starting frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Loop over frames in the specified range\n",
    "for i in range(start_frame, end_frame):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Crop the central 80% of the frame\n",
    "    height, width = frame.shape[:2]\n",
    "    crop_width = int(width * 0.8)\n",
    "    crop_height = int(height * 0.8)\n",
    "    x_start = (width - crop_width) // 2\n",
    "    y_start = (height - crop_height) // 2\n",
    "    frame_cropped = frame[y_start:y_start+crop_height, x_start:x_start+crop_width]\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame_cropped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow if there's a previous frame\n",
    "    if prev_gray is not None:\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        avg_magnitude = np.mean(mag)\n",
    "        optical_flow_values.append(avg_magnitude)\n",
    "\n",
    "    # Set the current frame to previous\n",
    "    prev_gray = gray\n",
    "\n",
    "# Downsample the optical flow values to 1Hz (1 value per second)\n",
    "downsampled_data = []\n",
    "for i in range(0, len(optical_flow_values)):\n",
    "    sample_mean = np.mean(optical_flow_values[i:i+fps])\n",
    "    sample_median = np.median(optical_flow_values[i:i+fps])\n",
    "    downsampled_data.append({'mean': sample_mean, 'median': sample_median})\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(downsampled_data)\n",
    "\n",
    "# Output the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jyoti\\anaconda3\\envs\\save\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.418124</td>\n",
       "      <td>3.327080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.446643</td>\n",
       "      <td>1.751254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.073743</td>\n",
       "      <td>0.010429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.573835</td>\n",
       "      <td>2.255070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.447178</td>\n",
       "      <td>3.289779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.304537</td>\n",
       "      <td>4.301511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.849064</td>\n",
       "      <td>10.093546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean      median\n",
       "count  898.000000  898.000000\n",
       "mean     3.418124    3.327080\n",
       "std      1.446643    1.751254\n",
       "min      0.073743    0.010429\n",
       "25%      2.573835    2.255070\n",
       "50%      3.447178    3.289779\n",
       "75%      4.304537    4.301511\n",
       "max      8.849064   10.093546"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fms\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "..   ...\n",
       "835    2\n",
       "836    2\n",
       "837    2\n",
       "838    2\n",
       "839    2\n",
       "\n",
       "[840 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"fms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fms</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.178822</td>\n",
       "      <td>0.154815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.084262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.100199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121259</td>\n",
       "      <td>0.119429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.089803</td>\n",
       "      <td>0.093231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2</td>\n",
       "      <td>2.580304</td>\n",
       "      <td>3.019026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>2</td>\n",
       "      <td>2.793762</td>\n",
       "      <td>1.174016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>2</td>\n",
       "      <td>4.629346</td>\n",
       "      <td>4.088746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2</td>\n",
       "      <td>3.701176</td>\n",
       "      <td>3.504064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2</td>\n",
       "      <td>4.108211</td>\n",
       "      <td>4.303681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fms      mean    median\n",
       "0      1  0.178822  0.154815\n",
       "1      1  0.100140  0.084262\n",
       "2      1  0.104509  0.100199\n",
       "3      1  0.121259  0.119429\n",
       "4      1  0.089803  0.093231\n",
       "..   ...       ...       ...\n",
       "835    2  2.580304  3.019026\n",
       "836    2  2.793762  1.174016\n",
       "837    2  4.629346  4.088746\n",
       "838    2  3.701176  3.504064\n",
       "839    2  4.108211  4.303681\n",
       "\n",
       "[840 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_series_data(data, time_step=1, output_dim=1, drop_na=True):\n",
    "  n_vars = 1 if type(data) is list else data.shape[1]\n",
    "  df = pd.DataFrame(data)\n",
    "  cols, names = list(), list()\n",
    "  for i in range(time_step, 0, -1):\n",
    "      cols.append(df.shift(i))\n",
    "      names += [('X%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "  for i in range(0, output_dim):\n",
    "      cols.append(df.shift(-i))\n",
    "      if i == 0:\n",
    "          names += [('Y%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "      else:\n",
    "          names += [('Y%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "  aggregated_data = pd.concat(cols, axis=1)\n",
    "  aggregated_data.columns = names\n",
    "  if drop_na:\n",
    "      aggregated_data.dropna(inplace=True)\n",
    "  return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1(t-30)</th>\n",
       "      <th>X2(t-30)</th>\n",
       "      <th>X3(t-30)</th>\n",
       "      <th>X1(t-29)</th>\n",
       "      <th>X2(t-29)</th>\n",
       "      <th>X3(t-29)</th>\n",
       "      <th>X1(t-28)</th>\n",
       "      <th>X2(t-28)</th>\n",
       "      <th>X3(t-28)</th>\n",
       "      <th>X1(t-27)</th>\n",
       "      <th>...</th>\n",
       "      <th>X3(t-3)</th>\n",
       "      <th>X1(t-2)</th>\n",
       "      <th>X2(t-2)</th>\n",
       "      <th>X3(t-2)</th>\n",
       "      <th>X1(t-1)</th>\n",
       "      <th>X2(t-1)</th>\n",
       "      <th>X3(t-1)</th>\n",
       "      <th>Y1(t)</th>\n",
       "      <th>Y2(t)</th>\n",
       "      <th>Y3(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.178822</td>\n",
       "      <td>0.154815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173790</td>\n",
       "      <td>0.136031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.255108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381167</td>\n",
       "      <td>0.351902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121259</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.255108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381167</td>\n",
       "      <td>0.351902</td>\n",
       "      <td>1</td>\n",
       "      <td>1.192985</td>\n",
       "      <td>1.456125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1(t-30)  X2(t-30)  X3(t-30)  X1(t-29)  X2(t-29)  X3(t-29)  X1(t-28)  \\\n",
       "30       1.0  0.178822  0.154815       1.0  0.100140  0.084262       1.0   \n",
       "31       1.0  0.100140  0.084262       1.0  0.104509  0.100199       1.0   \n",
       "\n",
       "    X2(t-28)  X3(t-28)  X1(t-27)  ...   X3(t-3)  X1(t-2)   X2(t-2)   X3(t-2)  \\\n",
       "30  0.104509  0.100199       1.0  ...  0.117719      1.0  0.173790  0.136031   \n",
       "31  0.121259  0.119429       1.0  ...  0.136031      1.0  0.387818  0.255108   \n",
       "\n",
       "    X1(t-1)   X2(t-1)   X3(t-1)  Y1(t)     Y2(t)     Y3(t)  \n",
       "30      1.0  0.387818  0.255108      1  0.381167  0.351902  \n",
       "31      1.0  0.381167  0.351902      1  1.192985  1.456125  \n",
       "\n",
       "[2 rows x 93 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_horizon = 1\n",
    "time_lag = 30\n",
    "\n",
    "# Convert the data to time-series\n",
    "train_hr_data_ml = prepare_time_series_data(data=df, time_step=time_lag, output_dim=forecast_horizon)\n",
    "test_hr_data_ml =  prepare_time_series_data(data=df, time_step=time_lag, output_dim=forecast_horizon)\n",
    "train_hr_data_ml.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2(t-30)</th>\n",
       "      <th>X3(t-30)</th>\n",
       "      <th>X2(t-29)</th>\n",
       "      <th>X3(t-29)</th>\n",
       "      <th>X2(t-28)</th>\n",
       "      <th>X3(t-28)</th>\n",
       "      <th>X2(t-27)</th>\n",
       "      <th>X3(t-27)</th>\n",
       "      <th>X2(t-26)</th>\n",
       "      <th>X3(t-26)</th>\n",
       "      <th>...</th>\n",
       "      <th>X2(t-4)</th>\n",
       "      <th>X3(t-4)</th>\n",
       "      <th>X2(t-3)</th>\n",
       "      <th>X3(t-3)</th>\n",
       "      <th>X2(t-2)</th>\n",
       "      <th>X3(t-2)</th>\n",
       "      <th>X2(t-1)</th>\n",
       "      <th>X3(t-1)</th>\n",
       "      <th>Y1(t)</th>\n",
       "      <th>Y3(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.178822</td>\n",
       "      <td>0.154815</td>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.121259</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>0.089803</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121841</td>\n",
       "      <td>0.110027</td>\n",
       "      <td>0.112853</td>\n",
       "      <td>0.117719</td>\n",
       "      <td>0.173790</td>\n",
       "      <td>0.136031</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.255108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.121259</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>0.089803</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>0.109756</td>\n",
       "      <td>0.107062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112853</td>\n",
       "      <td>0.117719</td>\n",
       "      <td>0.173790</td>\n",
       "      <td>0.136031</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.255108</td>\n",
       "      <td>0.381167</td>\n",
       "      <td>0.351902</td>\n",
       "      <td>1</td>\n",
       "      <td>1.456125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X2(t-30)  X3(t-30)  X2(t-29)  X3(t-29)  X2(t-28)  X3(t-28)  X2(t-27)  \\\n",
       "30  0.178822  0.154815  0.100140  0.084262  0.104509  0.100199  0.121259   \n",
       "31  0.100140  0.084262  0.104509  0.100199  0.121259  0.119429  0.089803   \n",
       "\n",
       "    X3(t-27)  X2(t-26)  X3(t-26)  ...   X2(t-4)   X3(t-4)   X2(t-3)   X3(t-3)  \\\n",
       "30  0.119429  0.089803  0.093231  ...  0.121841  0.110027  0.112853  0.117719   \n",
       "31  0.093231  0.109756  0.107062  ...  0.112853  0.117719  0.173790  0.136031   \n",
       "\n",
       "     X2(t-2)   X3(t-2)   X2(t-1)   X3(t-1)  Y1(t)     Y3(t)  \n",
       "30  0.173790  0.136031  0.387818  0.255108      1  0.351902  \n",
       "31  0.387818  0.255108  0.381167  0.351902      1  1.456125  \n",
       "\n",
       "[2 rows x 62 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hr_data_ml = train_hr_data_ml[train_hr_data_ml.columns[~train_hr_data_ml.columns.to_series().str.contains(pat='X1\\(')]]\n",
    "train_hr_data_ml = train_hr_data_ml[train_hr_data_ml.columns[~train_hr_data_ml.columns.to_series().str.contains(pat='Y2\\(')]]\n",
    "\n",
    "test_hr_data_ml = test_hr_data_ml[test_hr_data_ml.columns[~test_hr_data_ml.columns.to_series().str.contains(pat='X1\\(')]]\n",
    "test_hr_data_ml = test_hr_data_ml[test_hr_data_ml.columns[~test_hr_data_ml.columns.to_series().str.contains(pat='Y2\\(')]]\n",
    "\n",
    "\n",
    "train_hr_data_ml.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_data(data, time_step, number_of_features):\n",
    "  values = data.values\n",
    "  number_observation = time_step * number_of_features\n",
    "  X, Y = values[:, :number_observation], values[:, -2]\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X = scaler.fit_transform(X)\n",
    "  X = X.reshape((X.shape[0], time_step, number_of_features))  # Reshape as (sample, time_step, features)\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape as (sample, time_step, features)\n",
      "\n",
      "Train HR data shape:  (810, 30, 1)\n",
      "Train HR Target shape:  (810,)\n",
      "Test HR data shape:  (810, 30, 1)\n",
      "Test HR Target shape:  (810,)\n"
     ]
    }
   ],
   "source": [
    "train_HR_X, train_HR_Y = get_x_y_data(data=train_hr_data_ml, time_step=30,\n",
    "                                      number_of_features=1) # Note HR data has only one featue which is the HR value\n",
    "\n",
    "\n",
    "test_HR_X, test_HR_Y = get_x_y_data(data=test_hr_data_ml, time_step=30,\n",
    "                                      number_of_features=1)\n",
    "\n",
    "print(\"Reshape as (sample, time_step, features)\\n\")\n",
    "print(\"Train HR data shape: \", train_HR_X.shape)\n",
    "print(\"Train HR Target shape: \", train_HR_Y.shape)\n",
    "\n",
    "print(\"Test HR data shape: \", test_HR_X.shape)\n",
    "print(\"Test HR Target shape: \", test_HR_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Input, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lstm(input_shape):\n",
    "  if not input_shape:\n",
    "      print(\"Error No input shape defined\")\n",
    "      return\n",
    "  input_layer = Input(shape=input_shape)\n",
    "  X = LSTM(60, return_sequences=True)(input_layer)\n",
    "  X = LSTM(120, recurrent_dropout=0.2)(X)\n",
    "  X = Dense(256, activation='relu')(X)\n",
    "  X = Dropout(0.2)(X)\n",
    "  output = Dense(64, activation='relu')(X)\n",
    "  return input_layer, output\n",
    "\n",
    "def get_regression_model(input_layers, output_layers, merge=True):\n",
    "  if merge:\n",
    "      merge_layer = concatenate(output_layers)\n",
    "  else:\n",
    "      merge_layer = output_layers[0]\n",
    "  final = Dense(1)(merge_layer)\n",
    "  model = Model(input_layers, outputs=final)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jyoti\\anaconda3\\envs\\save\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_layer1, output1 = get_lstm(input_shape=(30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 30, 60)            14880     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 120)               86880     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               30976     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " concatenate (Concatenate)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149249 (583.00 KB)\n",
      "Trainable params: 149249 (583.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regression_model = get_regression_model(input_layers=[input_layer1],\n",
    "                                                    output_layers=[output1], merge=True)\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jyoti\\anaconda3\\envs\\save\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression_model.compile(loss='mse', optimizer='adam', metrics=['mae', 'msle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_HR_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\jyoti\\anaconda3\\envs\\save\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jyoti\\anaconda3\\envs\\save\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 5s 202ms/step - loss: 0.9466 - mae: 0.9724 - msle: 0.4404 - val_loss: 1.7815 - val_mae: 1.2445 - val_msle: 0.5689\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.5481 - mae: 0.7292 - msle: 0.2194 - val_loss: 0.5206 - val_mae: 0.5644 - val_msle: 0.0982\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2722 - mae: 0.2548 - msle: 0.0372 - val_loss: 0.3715 - val_mae: 0.4461 - val_msle: 0.0634\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0423 - mae: 0.1674 - msle: 0.0116 - val_loss: 0.4370 - val_mae: 0.4644 - val_msle: 0.0771\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0384 - mae: 0.1524 - msle: 0.0110 - val_loss: 0.3493 - val_mae: 0.3975 - val_msle: 0.0573\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0113 - mae: 0.0829 - msle: 0.0029 - val_loss: 0.3829 - val_mae: 0.3912 - val_msle: 0.0637\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0059 - mae: 0.0601 - msle: 0.0015 - val_loss: 0.3611 - val_mae: 0.3712 - val_msle: 0.0593\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0077 - mae: 0.0629 - msle: 0.0018 - val_loss: 0.3549 - val_mae: 0.3655 - val_msle: 0.0580\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0063 - mae: 0.0581 - msle: 0.0015 - val_loss: 0.3703 - val_mae: 0.3750 - val_msle: 0.0611\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0535 - msle: 0.0012 - val_loss: 0.3637 - val_mae: 0.3714 - val_msle: 0.0598\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0039 - mae: 0.0496 - msle: 9.8340e-04 - val_loss: 0.3569 - val_mae: 0.3696 - val_msle: 0.0584\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0040 - mae: 0.0499 - msle: 0.0010 - val_loss: 0.3812 - val_mae: 0.3883 - val_msle: 0.0634\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0042 - mae: 0.0511 - msle: 0.0011 - val_loss: 0.3518 - val_mae: 0.3671 - val_msle: 0.0574\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0041 - mae: 0.0515 - msle: 0.0010 - val_loss: 0.3870 - val_mae: 0.3958 - val_msle: 0.0646\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0053 - mae: 0.0592 - msle: 0.0014 - val_loss: 0.3642 - val_mae: 0.3660 - val_msle: 0.0599\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0042 - mae: 0.0530 - msle: 0.0010 - val_loss: 0.3751 - val_mae: 0.3801 - val_msle: 0.0621\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0039 - mae: 0.0499 - msle: 0.0010 - val_loss: 0.3609 - val_mae: 0.3651 - val_msle: 0.0592\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0037 - mae: 0.0486 - msle: 9.0674e-04 - val_loss: 0.3682 - val_mae: 0.3707 - val_msle: 0.0607\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0036 - mae: 0.0479 - msle: 9.2358e-04 - val_loss: 0.3602 - val_mae: 0.3647 - val_msle: 0.0591\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0031 - mae: 0.0445 - msle: 7.7811e-04 - val_loss: 0.3731 - val_mae: 0.3773 - val_msle: 0.0617\n"
     ]
    }
   ],
   "source": [
    "train_HR_X =np.asarray(train_HR_X[1:]).astype(int) \n",
    "train_HR_Y = np.asarray(train_HR_Y).astype(int)\n",
    "\n",
    "history = regression_model.fit(x=[train_HR_X], y=train_HR_Y, epochs=20,\n",
    "                                   batch_size=128, validation_split=0.2, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 128\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m    127\u001b[0m video_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m29_video.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m14_video.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m17_video.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m23_video.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18_video.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Add your video file paths here\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m final_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Output the DataFrame\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_dataframe)\n",
      "Cell \u001b[1;32mIn[1], line 95\u001b[0m, in \u001b[0;36mprocess_videos\u001b[1;34m(video_files)\u001b[0m\n\u001b[0;32m     91\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_path \u001b[38;5;129;01min\u001b[39;00m video_files:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Open the video file to get fps and frame count\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[0;32m     96\u001b[0m     fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS))\n\u001b[0;32m     97\u001b[0m     total_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_COUNT))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_optical_flow(video_path, start_frame, end_frame):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_gray = None\n",
    "    optical_flow_values = []\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    for i in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width = frame.shape[:2]\n",
    "        crop_width = int(width * 0.8)\n",
    "        crop_height = int(height * 0.8)\n",
    "        x_start = (width - crop_width) // 2\n",
    "        y_start = (height - crop_height) // 2\n",
    "        frame_cropped = frame[y_start:y_start+crop_height, x_start:x_start+crop_width]\n",
    "\n",
    "        gray = cv2.cvtColor(frame_cropped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if prev_gray is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            avg_magnitude = np.mean(mag)\n",
    "            optical_flow_values.append(avg_magnitude)\n",
    "\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    downsampled_data = []\n",
    "    for i in range(0, len(optical_flow_values)):\n",
    "        sample_mean = np.mean(optical_flow_values[i:i+fps])\n",
    "        sample_median = np.median(optical_flow_values[i:i+fps])\n",
    "        downsampled_data.append({'mean_optical_flow': sample_mean, 'median_optical_flow': sample_median})\n",
    "\n",
    "    return pd.DataFrame(downsampled_data)\n",
    "\n",
    "def extract_hog_features(video_path, start_frame, end_frame):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    hog_features = []\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    for i in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray_frame = rgb2gray(frame)\n",
    "        hog_feature, _ = hog(gray_frame, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=True)\n",
    "        hog_features.append(hog_feature)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    downsampled_hog = []\n",
    "    for i in range(0, len(hog_features)):\n",
    "        sample_hog = np.mean(hog_features[i:i+fps], axis=0)\n",
    "        downsampled_hog.append(sample_hog)\n",
    "\n",
    "    return downsampled_hog\n",
    "\n",
    "def extract_color_histogram(video_path, start_frame, end_frame):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    histograms = []\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    for i in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        hist_b = cv2.calcHist([frame], [0], None, [256], [0, 256])\n",
    "        hist_g = cv2.calcHist([frame], [1], None, [256], [0, 256])\n",
    "        hist_r = cv2.calcHist([frame], [2], None, [256], [0, 256])\n",
    "        \n",
    "        histograms.append(np.concatenate((hist_b, hist_g, hist_r)).flatten())\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    downsampled_hist = []\n",
    "    for i in range(0, len(histograms)):\n",
    "        sample_hist = np.mean(histograms[i:i+fps], axis=0)\n",
    "        downsampled_hist.append(sample_hist)\n",
    "\n",
    "    return downsampled_hist\n",
    "\n",
    "def process_videos(video_files):\n",
    "    all_data = []\n",
    "\n",
    "    for video_path in video_files:\n",
    "        # Open the video file to get fps and frame count\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        cap.release()\n",
    "        \n",
    "        # Calculate start and end frames for the last 15 minutes, excluding the last 60 seconds\n",
    "        duration_seconds = 15 * 60  # 15 minutes in seconds\n",
    "        frames_to_process = duration_seconds * fps\n",
    "        end_frame = total_frames - (60 * fps)  # Exclude the last 60 seconds\n",
    "        start_frame = max(0, end_frame - frames_to_process)\n",
    "\n",
    "        # Extract features\n",
    "        optical_flow_df = extract_optical_flow(video_path, start_frame, end_frame)\n",
    "        downsampled_hog = extract_hog_features(video_path, start_frame, end_frame)\n",
    "        downsampled_hist = extract_color_histogram(video_path, start_frame, end_frame)\n",
    "\n",
    "        # Ensure the downsampled data for HOG and color histogram are 1Hz and have 900 samples\n",
    "        hog_df = pd.DataFrame(downsampled_hog, columns=[f'hog_{i}' for i in range(len(downsampled_hog[0]))])\n",
    "        hist_df = pd.DataFrame(downsampled_hist, columns=[f'hist_{i}' for i in range(len(downsampled_hist[0]))])\n",
    "\n",
    "        # Combine all features into a single DataFrame\n",
    "        combined_df = optical_flow_df.copy()\n",
    "        combined_df = pd.concat([combined_df, hog_df, hist_df], axis=1)\n",
    "        combined_df['video_name'] = os.path.basename(video_path)  # Add video name for reference\n",
    "\n",
    "        all_data.append(combined_df)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into one\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "# Example usage:\n",
    "video_files = ['29_video.mkv', '14_video.mkv', '17_video.mkv', '23_video.mkv', '18_video.mkv']  # Add your video file paths here\n",
    "final_dataframe = process_videos(video_files)\n",
    "\n",
    "# Output the DataFrame\n",
    "print(final_dataframe)\n",
    "\n",
    "# Save to CSV if needed\n",
    "final_dataframe.to_csv('video_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "save",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
